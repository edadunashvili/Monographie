{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Arbeitplatz vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/edadunashvili/Monographie.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/Monographie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zelle # 1] - Modul für die Aggregation des Korpus von gelabelte Daten\n",
    "\n",
    "1 - 5: Funktion für das Löschen der alte Dateien.\n",
    "\n",
    "6 -62: Aggregation der Datei 'episode_temp_valid.csv'. Die  im Ordner 'Repository' angelegte TXT Dateien werden in der CSV Datei aggregiert und in das Repositorium neben den Validation-Notebook verlegt.\n",
    "\n",
    "63 - 69: Umwandlung 'episode_temp_valid.csv' in die Datei 'episode_string_valid.csv'.\n",
    "\n",
    "70: Unnötige Aggregation wird gelöscht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entfernen(var):\n",
    "    import os\n",
    "    if os.path.exists(var):\n",
    "        os.remove(var)\n",
    "entfernen(\"episode_string_valid.csv\")\n",
    "import glob\n",
    "def word_to_lex(word):\n",
    "    ret=(word) \n",
    "    return ret\n",
    "def write_back(words):\n",
    "    with open(\"episode_temp_valid.csv\",\"a\", encoding='utf-8') as output:\n",
    "        for word in words:\n",
    "            as_lex = word_to_lex(word[0])\n",
    "            full_word = '\"' + as_lex + '\"'\n",
    "            for sub_word in word[1:]:\n",
    "                full_word += \" , \"  '\"' + sub_word + '\"'\n",
    "            full_word +=\"\\n\"\n",
    "            output.write(full_word)\n",
    "def clean(line):\n",
    "    line = line.replace(\"\\n\",\" \").strip()\n",
    "    line = line.replace(\"ä\",\"ae\").replace(\"ü\",\"ue\").replace(\"ö\",\"oe\")\n",
    "    line = line.replace(\"ß\",\"ss\").replace(\",\",\"\").replace(\"«\",\"\")\n",
    "    line = line.replace(\"»\",\"\").replace(\".\",\"\").replace(\":\",\"\")\n",
    "    line = line.replace(\";\",\"\").replace('\"',\"\")\n",
    "    line = line.replace(\"?\",\"\").replace(\"!\",\"\").replace(\"á\",\"a\")\n",
    "    line = line.replace(\",\",\"\").replace(\"\\t\",\" \").replace(\"'\",\"\")\n",
    "    line = line.replace(\"‹\",\"\").replace(\"›\",\"\").replace(\"-\",\" \")\n",
    "    line = line.replace(\"'('\",\"\").replace(\"')'\",\"\").replace('>','')\n",
    "    line = line.replace(\"    \",\" \").replace(\"   \",\" \").replace(\"  \",\" \")\n",
    "    line = line.replace('–','').replace('—','').replace('<','')\n",
    "    line = line.replace(\"Â\", \"A\").replace(\"ø\", \"oe\").replace('“','')\n",
    "    line = line.replace('„','').replace('(','').replace(')','')\n",
    "    line = line.replace(\"‚\", \"\").replace(']','').replace('[','')\n",
    "    if line == \"\": \n",
    "        return\n",
    "    line=line.split(\"|\")\n",
    "    line[0]=line[0].split(\"|\")[0]\n",
    "    for i, _ in enumerate(line):\n",
    "        if (i !=0) and (i!=2):\n",
    "            line[i]=line[i].lower()\n",
    "    flex=[]\n",
    "    try:\n",
    "        flex=line[1].split(\"\")\n",
    "    except:\n",
    "        pass\n",
    "    value=str(line)\n",
    "    line=str(line)   \n",
    "    flex.append(line)\n",
    "    ret=[]\n",
    "    for i in flex:\n",
    "        ret.append((i,value[0]))\n",
    "    return ret\n",
    "with open(\"episode_temp_valid.csv\", \"w\", encoding='utf-8') as output:\n",
    "    output.write (\"quelle,episode,index_string,index_binar\\n\")\n",
    "pairs = []\n",
    "for file in glob.glob(\"Forschungsdaten/*.txt\"):\n",
    "        with open(file, 'r', encoding='utf-8', errors='ignore') as episode:\n",
    "            for line in episode.readlines():\n",
    "                clean_words = clean(line)\n",
    "                pairs = pairs + clean_words\n",
    "write_back(pairs)\n",
    "fin = open(\"episode_temp_valid.csv\",'r', encoding ='utf-8')\n",
    "fout = open('episode_string_valid.csv', \"wt\", encoding ='utf-8')\n",
    "for kfz in fin:\n",
    "    fout.write(kfz.replace(', \"[\"',\"\").replace('\"[', \"\")\n",
    "               .replace(']\"',\"\").replace(\"', '\", \"','\")\n",
    "               .replace(\" '\", \"'\").replace(\"'\",\"\"))                      \n",
    "fin.close()\n",
    "fout.close()\n",
    "entfernen(\"episode_temp_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zelle # 2] - Modul für die Aggregation der im Markup vorhandene Episodenliste\n",
    "\n",
    "1: Alte Liste löschen (falls vorhanden).\n",
    "\n",
    "2 - 23: Episodenliste in eine CSV-Tempdatei anlegen, von der zusätzliche Zeichen bereinigen und in die Datei 'liste_string_valid.csv' anlegen. \n",
    "\n",
    "24: Unnötige Aggregation wird gelöscht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "entfernen('liste_markup_valid.csv' )\n",
    "import glob\n",
    "import csv \n",
    "import shutil, os\n",
    "def write_back(lines):\n",
    "    with open(\"liste_temp_valid.csv\",\"a\", encoding='utf-8') as output:\n",
    "        for line in lines:        \n",
    "            output.write(line)\n",
    "with open(\"liste_temp_valid.csv\", \"w\", encoding='utf-8') as output:\n",
    "    output.write (\"index_string\\n\")\n",
    "markup = []\n",
    "for file in glob.glob(\"Markup/*.txt\"): \n",
    "        with open(file, 'r', encoding='utf-8', errors='ignore') as episode:\n",
    "            for line in episode.readlines():\n",
    "                if line.startswith( \"e\" ) and '__' not in line:\n",
    "                    markup.append(line)\n",
    "write_back(markup)\n",
    "fin = open('liste_temp_valid.csv','r', encoding ='utf-8')\n",
    "fout = open('liste_markup_valid.csv', \"wt\", encoding ='utf-8')\n",
    "for kfz in fin:\n",
    "    fout.write(kfz.replace(\"'\",\"\"))                      \n",
    "fin.close()\n",
    "fout.close()\n",
    "entfernen('liste_temp_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zelle # 3] - Modul für die Gegenüberstellung der Markupliste und der Labels \n",
    "\n",
    "1 - 13: Rotmarkierte Werte stellen die Labels aus den Textdaten dar, die in den Markupliste keine adäquate Werte haben und umgekehrt, grüne Werte stellen die Elemente aus der Markupliste dar, die keine adäquate Werte in Textdaten haben. Im idealen Fall muss es keine rote Labels geben (ausgenomen Episoden mit einem '_a_' Suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m0\u001b[0m\n",
      "\u001b[31me302C*_a_\u001b[0m\n",
      "\u001b[31me303A_a_\u001b[0m\n",
      "\u001b[31me314_a_\u001b[0m\n",
      "\u001b[31me315_a_\u001b[0m\n",
      "\u001b[31me316_a_\u001b[0m\n",
      "\u001b[31me317_a_\u001b[0m\n",
      "\u001b[31me328_a_\u001b[0m\n",
      "\u001b[31me403_a_\u001b[0m\n",
      "\u001b[31me513a_a_\u001b[0m\n",
      "\u001b[31me516_a_\u001b[0m\n",
      "\u001b[31me518_a_\u001b[0m\n",
      "\u001b[31me550_a_\u001b[0m\n",
      "\u001b[31me555_a_\u001b[0m\n",
      "\u001b[31me562_a_\u001b[0m\n",
      "\u001b[31me567_a_\u001b[0m\n",
      "\u001b[31me590_a_\u001b[0m\n",
      "\u001b[31me613_a_\u001b[0m\n",
      "\u001b[31me673_a_\u001b[0m\n",
      "\u001b[31me850_a_\u001b[0m\n",
      "\u001b[31meUNDF_a_\u001b[0m\n",
      "\u001b[32me302_e_erprobung_der_faehigkeiten_des_HD\u001b[0m\n",
      "\u001b[32me302_g_begegnung_des_HD_und_des_ST_bis_zur_ausruestung_des_HD\u001b[0m\n",
      "\u001b[32me329_c_eingangsepisode_bis_zur_ankundigung_der_heiratsbedingungen_und_reaktion_des_freiers\u001b[0m\n",
      "\u001b[32me329_e_misslungener_versuch_des_FH_ohne_toedliche_konsequenzen\u001b[0m\n",
      "\u001b[32me329_g_misslungener_versuch_des_FH_mit_toedliche_konsequenzen\u001b[0m\n",
      "\u001b[32me329_i_misslungener_versuch_des_HD\u001b[0m\n",
      "\u001b[32me329_k_ erfolgreicher_versuch_des_HD_und_unterwerfung_der_herausforderin\u001b[0m\n",
      "\u001b[32me513A_c_begegnung_mit_dem_kuenftigen_HF_bis_zum_erreichen_des_reiseziels\u001b[0m\n",
      "\u001b[32me513A_e_vorletzte_aufgabe_und_ihre_loesung\u001b[0m\n",
      "\u001b[32me513A_g_letzte_aufgabe_und_ihre_loesung\u001b[0m\n",
      "\u001b[32me516_c_grund_für_die_freundschaft_zwischen_HD_und_HF\u001b[0m\n",
      "\u001b[32me516_e_fernliebe_bis_zum_auszug_auf_der_suche_nach_dem_OB\u001b[0m\n",
      "\u001b[32me516_g_ertste_begegnung_mit_dem_HF\u001b[0m\n",
      "\u001b[32me516_i_erste_belauschung_des_ST\u001b[0m\n",
      "\u001b[32me516_k_gewinnung_des_OB\u001b[0m\n",
      "\u001b[32me516_m_rueckkehr_und_belauschung_des_ST\u001b[0m\n",
      "\u001b[32me516_o_abwehr_der_vorletzten_gefahr\u001b[0m\n",
      "\u001b[32me516_q_abwehr_der_letzten_gefahr\u001b[0m\n",
      "\u001b[32me516_s_erklaerung_und_konsequenzen\u001b[0m\n",
      "\u001b[32me516_u_informationen_ueber_das_erloesungsmittel_bis_zur_erloesung\u001b[0m\n",
      "\u001b[32me516_w_glueckliches_ende\u001b[0m\n",
      "\u001b[32me531_c_eingangsepisode_bis_zur_beschaffung_des_vertvollen_gegenstandes\u001b[0m\n",
      "\u001b[32me531_e_besuch_beim_koenig_und_reaktion_des_koenigs\u001b[0m\n",
      "\u001b[32me531_g_stellen_einer_der_vorlezten_aufgaben\u001b[0m\n",
      "\u001b[32me531_i_begednung_mit_dem_HF\u001b[0m\n",
      "\u001b[32me531_k_erfuellung_einer_der_vorletzten_aufgaben\u001b[0m\n",
      "\u001b[32me531_m_stellen_der_letzten_aufgabe\u001b[0m\n",
      "\u001b[32me531_o_letzte_begegnung_mit_dem_HF\u001b[0m\n",
      "\u001b[32me531_q_erfuellung_der_letzten_aufgabe\u001b[0m\n",
      "\u001b[32me531_s_strafe_statt_hochzeit_bis_zum_ende\u001b[0m\n",
      "\u001b[32me554_c_missachtung_des_tieres\u001b[0m\n",
      "\u001b[32me707_c_aussetzen_des_kindes_bis_zum_kontakt_mit_dem_kuenftigem_braeutigam\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"episode_string_valid.csv\", encoding='utf-8')\n",
    "df2 = pd.read_csv(\"liste_markup_valid.csv\", encoding='utf-8')\n",
    "listA=(df1['index_string'])\n",
    "listB=(df2['index_string'])\n",
    "from termcolor import colored\n",
    "AB=sorted(list(set(listA) ^ set(listB)))\n",
    "nurB=sorted(list(set(AB) & set(listB)))\n",
    "nurA=sorted(list(set(AB) & set(listA)))\n",
    "for elementA in nurA:\n",
    "    print(colored(elementA,\"red\"))\n",
    "for elementB in nurB:\n",
    "    print(colored(elementB,\"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zelle #4] - Extraliste für die bestimte Episodengruppe\n",
    "\n",
    "1: Episodengruppe bestimmen\n",
    "\n",
    "2: Labels von Textdateien ('listA') oder Elemente aus dem Markup ('listB' bestimmen  \n",
    "\n",
    "3-4: In der Zeile 2 bestimmte Liste abrufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e650A_e_verlassen_des_hauses_bis_zum_treffen_mit_dem_AN\n",
      "e650A_g_zum_besuch_beim_AN_und_die_reaktion_des_AN\n",
      "e650A_i_eine_der_vorlezten_aufgaben\n",
      "e650A_k_die_letzte_aufgabe\n",
      "e650A_m_nach_der_erfuellung_der_letzte_aufgabe_bis_zum_ende_der_geschichte\n",
      "e650A_k_die_letzte_aufgabe\n",
      "e650A_m_nach_der_erfuellung_der_letzte_aufgabe_bis_zum_ende_der_geschichte\n"
     ]
    }
   ],
   "source": [
    "egruppe='e650A_'\n",
    "for find in listB: # alternativ 'lisA'\n",
    "    if egruppe in find:\n",
    "        print(find)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ende"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
